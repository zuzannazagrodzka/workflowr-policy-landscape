---
title: "5_For_and_not_for_profit_comparison"
author: "ZZ, APB, TFJ"
# author: "zuzannazagrodzka"
date: "`r Sys.Date()`"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

There are two questions we did not address formally in the manuscript because of too small sample size. 

- What language do for-profit and not-for-profit publishers use in their mission statements and aims?
- What organisations use more common language to the UNESCO Recommendations in Open Science and which use business words? 

We conducted the same language analysis that were conducted on the main stakeholders groups to compare for-profit vs. not-for-profit publishers and nonOA journals vs. OA journals. 

# R Step and Packages

```{r, message=FALSE}
# Clearing R
rm(list=ls())

# Libraries used for text/data analysis
library(tidyverse) 
library(dplyr)
library(tidytext)

# Libraries used to create plots
library(ggplot2)

# Library to create a table when converting to html
library("kableExtra") 

```


# Importing data

```{r}

# Importing dataset created in "1a_Data_preprocessing.Rmd"
# df_corpuses <- read.csv(file = "./output/created_datasets/cleaned_data.csv")

# Importing dataset that we originally created and used in our analysis
df_corpuses <- read.csv(file = "./data/original_dataset_reproducibility_check/original_cleaned_data.csv")

data_words <- df_corpuses

# Dictionary data 
# Importing dictionary data that we originally created and used in our analysis
all_dict <- read.csv(file = "./data/original_dataset_reproducibility_check/original_freq_dict_total_all.csv")

```

# Data Prep and Cleaning

``` {r}
# Data preparation

# Changing name of the dictionary variable
new_dictionary <- all_dict

## Getting a data set with the words
data_words <- df_corpuses

dim(data_words)
colnames(data_words)
unique(data_words$org_subgroups)
# Merging and removing duplicates
data_words <- data_words %>% 
  rename(document = name) %>% 
  select(document, org_subgroups, word) %>% 
  left_join(new_dictionary, by = c("word" = "word")) %>% # merging
  filter(org_subgroups %in% c("publishers_nonProfit", "publishers_Profit", "journals_nonOA", "journals_OA"))

```



```{r}
# Transforming the data frame
# data_words <- transform(data_words, present_BUS = as.numeric(present_BUS), 
                    # present_UNESCO = as.numeric(present_UNESCO), 
                    # present_book = as.numeric(present_book))

# Adding a column with stakeholder and word together to allow merging later
data_words$stake_word <- paste(data_words$org_subgroups, "_", data_words$word)
# Adding a column with a document name and word together to allow merging later
data_words$doc_word <- paste(data_words$document, "_", data_words$word)
# Adding a column that will be used later to calculate the total of unique words in the document (dictionaries without removed words)
data_words$doc_pres <- 1

# Adding two columns that will be used later to calculate the total of unique words in the document (new dictionaries with removed common words)
# Replace NAs with 0 in all absence/presence columns
data_words_ND <- data_words %>%
  mutate_at(vars(present_BUS, present_UNESCO, present_book, sum), ~replace_na(., 0)) # replacing NAs
  
head(data_words_ND,3)
colnames(data_words_ND)

## Preparing columns used to creating ternary plots
# Select columns of my interest (stakeholders) and aggregate 
  
data_words_ND <- data_words_ND %>% 
  select(document, org_subgroups, word, present_BUS, present_UNESCO, present_book, doc_pres, sum) # selecting columns, sum - column with the information about in how many dictionaries a certain word occurs

df_sum_pres_ND <- aggregate(x = data_words_ND[,4:8], by = list(data_words_ND$document), FUN = sum, na.rm = TRUE)
  
# By doing aggregate I lost info about the org_subgroups the doc come from, I want to add it
df_doc_ord <- data_words_ND %>% 
  select(document, org_subgroups) %>% 
  distinct(document, .keep_all = TRUE)
  
df_sum_pres_ND <- df_sum_pres_ND %>% 
  left_join(df_doc_ord, by = c("Group.1" = "document")) %>% 
  rename(document = Group.1)

# Creating % columns in a new df_sum_proc_ND data frame 
df_sum_proc_ND <- df_sum_pres_ND
# View(df_sum_proc_ND)

df_sum_proc_ND$proc_BUS <-df_sum_proc_ND$present_BUS/df_sum_proc_ND$doc_pres*100
df_sum_proc_ND$proc_UNESCO <- df_sum_proc_ND$present_UNESCO/df_sum_proc_ND$doc_pres*100
df_sum_proc_ND$proc_book <- df_sum_proc_ND$present_book/df_sum_proc_ND$doc_pres*100


# Additional information about the data
# Stakeholders (2 from each of the stakeholders) that shared the highest no of words with UNESCO recommendation

UNESCO_stak_top <- df_sum_proc_ND %>% 
  group_by(org_subgroups) %>% 
  arrange(desc(proc_UNESCO)) %>% 
  slice_head(n=2) %>% 
  select(org_subgroups, document, proc_UNESCO)

UNESCO_stak_top %>% 
  kbl(caption = "Stakeholders that shared the higest no of words with UNESCO recommendation:") %>% 
  kable_classic("hover", full_width = T)

# Stakeholders (2 from each of the stakeholders) that shared the highest no of words with business dictionary

business_stak_top <- df_sum_proc_ND %>% 
  group_by(org_subgroups) %>% 
  arrange(desc(proc_BUS)) %>% 
  slice_head(n=2) %>% 
  select(org_subgroups, document, proc_BUS)

business_stak_top %>% 
  kbl(caption = "Stakeholders that shared the higest no of words with business dictionary:") %>% 
  kable_classic("hover", full_width = T)

# Stakeholders (2 from each of the stakeholders) that shared the highest no of words with book dictionary (control)

book_stak_top <-  df_sum_proc_ND %>% 
  group_by(org_subgroups) %>% 
  arrange(desc(proc_book)) %>% 
  slice_head(n=2) %>% 
  select(org_subgroups, document, proc_book)

book_stak_top %>% 
  kbl(caption = "Stakeholders that shared the higest no of words with book dictionary (control):") %>% 
  kable_classic("hover", full_width = T)

```

# Creating graphs

```{r}
no <- nrow(df_sum_proc_ND)
no

# Plotting them separately book
df_sum_proc_ND_book = data.frame(
  document = rep(df_sum_proc_ND$document,1),
  org_subgroups = rep(df_sum_proc_ND$org_subgroups,1),
  type = c(rep("Book",no)),
  perc = c(df_sum_proc_ND$proc_book),
  perc2 = c(df_sum_proc_ND$proc_book))

sum_df_sum_proc_ND_book = 
  df_sum_proc_ND_book %>%
  group_by(org_subgroups, type) %>%
  # dplyr::summarise(perc = mean(perc), SD = sd(perc2))
  dplyr::summarise(perc = median(perc), SD = sd(perc2))

ggplot() +
  geom_point(data = df_sum_proc_ND_book, aes(x = perc, y = org_subgroups), alpha = 0.1, position = position_jitter()) +
  geom_pointrange(data = sum_df_sum_proc_ND_book, aes(x = perc, xmin = perc - SD, xmax = perc + SD, y = org_subgroups)) +
  facet_grid(type~.) +
  labs(x = "Document words occuring in dictionary (%)", y = "") +
  scale_colour_discrete(guide = "none") +
  theme_classic()

# Plotting them separately Business
df_sum_proc_ND_BUS = data.frame(
  document = rep(df_sum_proc_ND$document,1),
  org_subgroups = rep(df_sum_proc_ND$org_subgroups,1),
  type = c(rep("Business",no)),
  perc = c(df_sum_proc_ND$proc_BUS),
  perc2 = c(df_sum_proc_ND$proc_BUS))

sum_df_sum_proc_ND_BUS = 
  df_sum_proc_ND_BUS %>%
  group_by(org_subgroups, type) %>%
  # dplyr::summarise(perc = mean(perc), SD = sd(perc2))
  dplyr::summarise(perc = median(perc), SD = sd(perc2))

ggplot() +
  geom_point(data = df_sum_proc_ND_BUS, aes(x = perc, y = org_subgroups), alpha = 0.1, position = position_jitter()) +
  geom_pointrange(data = sum_df_sum_proc_ND_BUS, aes(x = perc, xmin = perc - SD, xmax = perc + SD, y = org_subgroups)) +
  facet_grid(type~.) +
  labs(x = "Document words occuring in dictionary (%)", y = "") +
  scale_colour_discrete(guide = "none") +
  theme_classic()


# Plotting them separately UNESCO
df_sum_proc_ND_UNESCO = data.frame(
  document = rep(df_sum_proc_ND$document,1),
  org_subgroups = rep(df_sum_proc_ND$org_subgroups,1),
  type = c(rep("UNESCO",no)),
  perc = c(df_sum_proc_ND$proc_UNESCO),
  perc2 = c(df_sum_proc_ND$proc_UNESCO))

sum_df_sum_proc_ND_UNESCO = 
  df_sum_proc_ND_UNESCO %>%
  group_by(org_subgroups, type) %>%
  # dplyr::summarise(perc = mean(perc), SD = sd(perc2))
  dplyr::summarise(perc = median(perc), SD = sd(perc2))

ggplot() +
  geom_point(data = df_sum_proc_ND_UNESCO, aes(x = perc, y = org_subgroups), alpha = 0.1, position = position_jitter()) +
  geom_pointrange(data = sum_df_sum_proc_ND_UNESCO, aes(x = perc, xmin = perc - SD, xmax = perc + SD, y = org_subgroups)) +
  facet_grid(type~.) +
  labs(x = "Document words occuring in dictionary (%)", y = "") +
  scale_colour_discrete(guide = "none") +
  theme_classic()


```


# Session information
``` {r}
sessionInfo()
```

